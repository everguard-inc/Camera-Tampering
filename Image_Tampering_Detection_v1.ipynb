{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import timeit\n",
    "from skimage import feature\n",
    "import glob\n",
    "import os\n",
    "import collections\n",
    "import scipy.signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GLCMFeature(frame,kernelSize):\n",
    "    kernel = np.ones((kernelSize,kernelSize),np.float32)/25\n",
    "\n",
    "    x = feature.greycomatrix(cv2.filter2D(frame,-1,kernel).astype('uint8'),distances=[10],angles=[180],normed=True,symmetric=True)\n",
    "    contrast = feature.greycoprops(x,prop='contrast')[0]\n",
    "    dissimilarity = feature.greycoprops(x,prop='dissimilarity')[0]\n",
    "    homogeneity = feature.greycoprops(x,prop='homogeneity')[0]\n",
    "    asm = feature.greycoprops(x,prop='ASM')[0]\n",
    "    energy = feature.greycoprops(x,prop='energy')[0]\n",
    "    \n",
    "    return [contrast,dissimilarity,homogeneity,asm,energy]\n",
    "\n",
    "def AGMM_Timer(queue):\n",
    "    if len(queue) != 10:\n",
    "        return False\n",
    "    tmp = queue[0]\n",
    "    for i in range(1,len(queue),1):\n",
    "        if tmp != queue[i] -1:\n",
    "            return False\n",
    "    return True\n",
    "    \n",
    "\n",
    "def aperture_effect(queue):\n",
    "    #print(queue)\n",
    "    if len(queue) <10:\n",
    "        return False\n",
    "    else:\n",
    "        last = queue[0]\n",
    "        for i in range(1,len(queue),1):\n",
    "            if last != queue[i] - 1:\n",
    "                return False\n",
    "            last = queue[i]\n",
    "    return True\n",
    "\n",
    "def defocus_delay(queue):\n",
    "    if len(queue) <10:\n",
    "        return False\n",
    "    else:\n",
    "        last = queue[0]\n",
    "        for i in range(1,len(queue),1):\n",
    "            if last != queue[i] - 1:\n",
    "                #print(\"\\t failed not connected\")\n",
    "                return False\n",
    "            last = queue[i]\n",
    "    #print(\"\\t returning True\")\n",
    "    return True\n",
    "\n",
    "\n",
    "def cross_image(im1, im2):\n",
    "    im1 -= np.mean(im1).astype('uint8')\n",
    "    im2 -= np.mean(im2).astype('uint8')\n",
    "\n",
    "    return scipy.signal.fftconvolve(im1, im2[::-1,::-1], mode='same')\n",
    "\n",
    "def k_largest_index_argpartition_v2(a, k):\n",
    "    idx = np.argpartition(a.ravel(),a.size-k)[-k:]\n",
    "    return np.column_stack(np.unravel_index(idx, a.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class subWindow():\n",
    "    def __init__(self,name,illuminationThreshold,textureThreshold,apertureLength,defocusThreshold,shiftTolerence,shiftRatio,learningRate):\n",
    "        self.name = name\n",
    "        self.trainingCache = collections.deque(maxlen = 2000)\n",
    "        self.illuminationModel = None\n",
    "        self.textureModel = None\n",
    "        self.cache = collections.deque(maxlen = 40)\n",
    "        self.shortTimeQue = collections.deque(maxlen = 20)\n",
    "        self.occlusionDelayQue = collections.deque(maxlen = 20)\n",
    "        self.defocusDelayQue = collections.deque(maxlen = 20)\n",
    "        self.AGMM = cv2.createBackgroundSubtractorMOG2()\n",
    "        self.shortAGMM = None\n",
    "        self.learningRate = learningRate\n",
    "        \n",
    "        self.illuminationThreshold1 = illuminationThreshold\n",
    "        self.illuminationThreshold2 = illuminationThreshold\n",
    "        self.textureThreshold1 = textureThreshold\n",
    "        self.textureThreshold2 = textureThreshold\n",
    "        self.textureThreshold3 = textureThreshold\n",
    "        self.textureThreshold4 = textureThreshold\n",
    "        \n",
    "        self.apertureLength = apertureLength\n",
    "        self.defocusThreshold = defocusThreshold\n",
    "        self.shiftTolerence = shiftTolerence\n",
    "        self.shiftRatio = shiftRatio\n",
    "        \n",
    "        self.avgPixel = 0\n",
    "        self.ORIGINALPOS = None\n",
    "        self.shift = 0\n",
    "    \n",
    "    def learningParam(self):\n",
    "\n",
    "        shift_value = []\n",
    "        shift_amount = []\n",
    "        illumination_value = []\n",
    "        texture_value = []\n",
    "        defocus_value = []\n",
    "        \n",
    "        ref_frame = np.zeros((self.trainingCache[0].shape[0],self.trainingCache[0].shape[1]))\n",
    "        \n",
    "        for i in range(len(self.trainingCache)):\n",
    "            fg = self.AGMM.apply(self.trainingCache[i],learningRate=-1)\n",
    "            ref_frame = ref_frame + self.trainingCache[i] - fg\n",
    "        \n",
    "        ref_frame = ref_frame / len(self.trainingCache)\n",
    "        \n",
    "        for i in range(0,len(self.trainingCache),1):\n",
    "            fg = self.AGMM.apply(self.trainingCache[i],learningRate = 0)\n",
    "            bg = self.trainingCache[i] - fg\n",
    "            \n",
    "            # illumination value\n",
    "            mean, std = np.mean(bg), np.std(bg)\n",
    "            illumination_value.append((mean,std))\n",
    "            \n",
    "            # GLCM value\n",
    "            a,b,c,d,e = GLCMFeature(bg,kernelSize=20)\n",
    "            texture_value.append((a,b,c,d,e))\n",
    "            \n",
    "            # AVG edge pixel number\n",
    "            defocus_value.append(sum(sum((bg>0))))\n",
    "            \n",
    "            \"\"\"# Shift value\n",
    "            corr = cross_image(bg,ref_frame)\n",
    "            \n",
    "            topk = k_largest_index_argpartition_v2(corr_img,5)\n",
    "            for k in topk:\n",
    "                corx, cory = k\n",
    "                shift_amount.append((corx,cory))\n",
    "            shift_value.append(max(corr))\n",
    "            \"\"\"\n",
    "        param = []\n",
    "        \"\"\"plt.plot(defocus_value)\n",
    "        plt.title(\"AVG pixel\")\n",
    "        plt.show()\"\"\"\n",
    "        defocusM = np.mean(defocus_value)\n",
    "        defocusS = np.std(defocus_value)\n",
    "        #print(max(abs(defocus_value-defocusM)),defocusM)\n",
    "        param.extend([defocusM,max(abs(defocus_value-defocusM))/defocusS])\n",
    "        \n",
    "        illuminaMean_list = np.array([x[0] for x in illumination_value])\n",
    "        \"\"\"plt.plot(illuminaMean_list)\n",
    "        plt.title(\"illumination Mean\")\n",
    "        plt.show()\"\"\"\n",
    "        illumin1M = np.mean(illuminaMean_list)\n",
    "        illumin1S = np.std(illuminaMean_list)\n",
    "        #print(max(abs(illuminaMean_list-illumin1M)),illumin1M)\n",
    "        param.append(max(abs(illuminaMean_list-illumin1M))/illumin1S)\n",
    "        \n",
    "        illuminaStd_list = np.array([x[1] for x in illumination_value])\n",
    "        \"\"\"plt.plot(illuminaStd_list)\n",
    "        plt.title(\"illumination Std\")\n",
    "        plt.show()\"\"\"\n",
    "        illumin2M = np.mean(illuminaMean_list)\n",
    "        illumin2S = np.std(illuminaMean_list)\n",
    "        #print(max(abs(illuminaMean_list-illumin2M)),illumin2M)\n",
    "        param.append(max(abs(illuminaMean_list-illumin2M))/illumin2S)\n",
    "        \n",
    "        textureDev = []\n",
    "        for i in range(len(texture_value[0])):\n",
    "            #print(\"Texture Feature  \",i)\n",
    "            tmp = np.array([x[i] for x in texture_value])\n",
    "            \"\"\"plt.plot(tmp)\n",
    "            plt.show()\"\"\"\n",
    "            tmpM = np.mean(tmp)\n",
    "            tmpS = np.std(tmp)\n",
    "            #print(max(abs(tmp-tmpM)),tmpM)\n",
    "            textureDev.append(max(abs(tmp-tmpM))/tmpS)\n",
    "        param.append(textureDev)\n",
    "        \n",
    "        self.settingParam(param)\n",
    "         \n",
    "    def settingParam(self,paramList):\n",
    "        avgP,defocus, illu1, illu2, textureDev = paramList\n",
    "        \n",
    "        self.illuminationThreshold1 = illu1\n",
    "        self.illuminationThreshold2 = illu2\n",
    "        self.avgPixel = avgP\n",
    "        self.defocusThreshold = defocus/2\n",
    "        self.textureThreshold1 = textureDev[0]*2\n",
    "        self.textureThreshold2 = textureDev[1]*2\n",
    "        self.textureThreshold3 = textureDev[2]*2\n",
    "        self.textureThreshold4 = textureDev[3]*2\n",
    "        self.textureThreshold5 = textureDev[4]*2\n",
    "        \n",
    "        \n",
    "        \n",
    "    def AGMMLearn(self):\n",
    "        for frame in self.cache:\n",
    "            self.AGMM.apply(frame,learningRate = -1)\n",
    "            \n",
    "    def computeAvgPixel(self):\n",
    "        edgepixel = []\n",
    "        for frame in self.cache:\n",
    "            edgepixel.append(sum(sum(frame)))\n",
    "        self.avgPixel = np.mean(edgepixel)\n",
    "        \n",
    "    def construct_illumination_model(self,init):\n",
    "        if init == 0:\n",
    "            video = self.cache\n",
    "        else:\n",
    "            video = self.trainingCache\n",
    "        meanLst = []\n",
    "        stdLst = []\n",
    "        for i in range(0,len(video),1):\n",
    "            meanLst.append(np.mean(video[i]))\n",
    "            stdLst.append(np.std(video[i]))\n",
    "        meanMean = np.mean(np.array(meanLst))\n",
    "        meanStd = np.std(np.array(meanLst))\n",
    "        stdMean = np.mean(np.array(stdLst))\n",
    "        stdStd = np.std(np.array(stdLst))\n",
    "        return [meanMean,meanStd,stdMean,stdStd]\n",
    "    \n",
    "    def suddenIlluminationChangeDetection(self):\n",
    "        frame = self.cache[-1]\n",
    "        tmpfg = frame - self.AGMM.apply(self.cache[-2],learningRate = 0)\n",
    "        meanMean,meanStd,stdMean,stdStd = self.illuminationModel\n",
    "        tmpmean = np.mean(frame)\n",
    "        tmpstd = np.std(frame)\n",
    "        #print(\"In ill Dect\",abs(tmpmean-meanMean),meanStd,abs(tmpstd-stdMean),stdStd)\n",
    "        if tmpmean > meanMean + self.illuminationThreshold1 * meanStd  or tmpmean < meanMean - self.illuminationThreshold1 * meanStd:\n",
    "            if tmpstd > stdMean + self.illuminationThreshold2 * stdStd or tmpstd < stdMean - self.illuminationThreshold2 * stdStd:\n",
    "                return True,(abs(tmpmean-meanMean)/meanStd,abs(tmpstd-stdMean)/stdStd)\n",
    "        return False,(abs(tmpmean-meanMean)/meanStd,abs(tmpstd-stdMean)/stdStd)\n",
    "    \n",
    "    def shiftDetection(self,illumi_flag,frameID):\n",
    "        frame = self.cache[-1]\n",
    "        if illumi_flag == 0:\n",
    "            tmpbg = self.cache[-1] - self.AGMM.apply(self.cache[-1],learningRate = 0)\n",
    "            corr_img = cross_image(tmpbg,self.ORIGINALPOS)\n",
    "            midx, midy = int(corr_img.shape[0]/2),int(corr_img.shape[1]/2)\n",
    "            norVale = corr_img[midx,midy]\n",
    "            corr_img[midx-self.shiftTolerence:midx+self.shiftTolerence,midy-self.shiftTolerence:midy+self.shiftTolerence] = 0\n",
    "            topk = k_largest_index_argpartition_v2(corr_img,5)\n",
    "            for k in topk:\n",
    "                corx, cory = k\n",
    "                \n",
    "                #print(frameID,corr_img[corx,cory]/norVale)\n",
    "                if corr_img[corx,cory]/norVale > self.shiftRatio:\n",
    "                    print(\" ===== Shift =====\",self.name)\n",
    "                    self.shift = 1\n",
    "                    break\n",
    "        else:\n",
    "            return (False, 0)\n",
    "            \n",
    "        if self.shift == 1:\n",
    "            return (True,corr_img[corx,cory]/norVale)\n",
    "        return (False, corr_img[corx,cory]/norVale)\n",
    "    \n",
    "    def construst_GLCM_model(self,init):\n",
    "        constrastLst =[]\n",
    "        dissimilarityLst = []\n",
    "        homogeneityLst = []\n",
    "        asmLst = []\n",
    "        energyLst = []\n",
    "        if init == 0:\n",
    "            video = self.trainingCache\n",
    "        else:\n",
    "            video = self.cache\n",
    "        for i in range(0,len(video),1):\n",
    "            a,b,c,d,e = GLCMFeature(video[i]-self.AGMM.apply(video[i],learningRate=0),20)\n",
    "            constrastLst.append(a)\n",
    "            dissimilarityLst.append(b)\n",
    "            homogeneityLst.append(c)\n",
    "            asmLst.append(d)\n",
    "            energyLst.append(e)\n",
    "        #print(\"Constructing Texture\",np.mean(constrastLst),np.std(constrastLst),np.mean(dissimilarityLst),np.std(dissimilarityLst),np.mean(homogeneityLst),np.std(homogeneityLst),np.mean(asmLst),np.std(asmLst),np.mean(energyLst),np.std(energyLst))\n",
    "        return [np.mean(constrastLst),np.std(constrastLst),np.mean(dissimilarityLst),np.std(dissimilarityLst),np.mean(homogeneityLst),np.std(homogeneityLst),np.mean(asmLst),np.std(asmLst),np.mean(energyLst),np.std(energyLst)]\n",
    "\n",
    "    def suddenTextureChangeDetection(self,frameID):\n",
    "        frame = self.cache[-1]\n",
    "        conM,conS,disM,disS,homM,homS,asmM,asmS,ergM,ergS = self.textureModel\n",
    "        tmpcon,tmpdis,tmphom,tmpasm,tmperg = GLCMFeature(frame,20)\n",
    "        \n",
    "        \n",
    "        if (tmpcon > conM + self.textureThreshold1 * conS or tmpcon < conM - self.textureThreshold1*conS) and (tmpdis > disM + self.textureThreshold2*disS or tmpdis < disM - self.textureThreshold2*disS) and (tmphom > homM + self.textureThreshold3*homS or tmphom < homM - self.textureThreshold3*homS) and (tmpasm > asmM + self.textureThreshold4*asmS or tmpasm < asmM - self.textureThreshold4*asmS) and (tmperg > ergM + self.textureThreshold5*ergS or tmperg < ergM - self.textureThreshold5*ergS):\n",
    "            self.occlusionDelayQue.append(frameID)\n",
    "            print(\" ===== texture change =====\",frameID,self.name)\n",
    "            return True,((abs(tmpcon-conM)/conS)[0],(abs(tmpdis-disM)/disS)[0],(abs(tmphom-homM)/homS)[0],(abs(tmpasm-asmM)/asmS)[0],(abs(tmperg-ergM)/ergS)[0])\n",
    "        \n",
    "        return False,((abs(tmpcon-conM)/conS)[0],(abs(tmpdis-disM)/disS)[0],(abs(tmphom-homM)/homS)[0],(abs(tmpasm-asmM)/asmS)[0],(abs(tmperg-ergM)/ergS)[0])\n",
    "    \n",
    "    def textureModelUpdate(self, illumi_flag,frameID):\n",
    "        frame = self.cache[-1]\n",
    "        if illumi_flag == 1:\n",
    "            if len(self.shortTimeQue) == 0:\n",
    "                self.shortAGMM = cv2.createBackgroundSubtractorMOG2()\n",
    "                self.shortAGMM.apply(frame - self.AGMM.apply(frame,learningRate=0),learningRate = self.learningRate)\n",
    "                self.shortTimeQue.append(frameID)\n",
    "            else:\n",
    "                self.shortAGMM.apply(frame, learningRate = self.learningRate)\n",
    "                self.shortTimeQue.append(frameID)\n",
    "                if AGMM_Timer(self.shortTimeQue):\n",
    "                    print(\" ===== Time \", frameID, \" Short AGMM Replace Long AGMM ===== \",self.name)\n",
    "                    self.AGMM = self.shortAGMM\n",
    "                    self.shortTimeQue.clear()\n",
    "                    self.shortAGMM = None\n",
    "                    self.illuminationModel = construct_illumination_model(self.cache)\n",
    "                    return True\n",
    "        else:\n",
    "            self.AGMM.apply(frame,learningRate = self.learningRate)\n",
    "            self.illuminationModel = self.construct_illumination_model(init = 1)\n",
    "            self.computeAvgPixel()\n",
    "        \n",
    "        return False\n",
    "        \n",
    "    def defocusDetection(self,illumi_flag, frameID):\n",
    "        frame = self.cache[-1]\n",
    "        #print(\"\\tCHECKING DECOFUS \\t \",sum(sum(frame - self.AGMM.apply(frame,learningRate = 0))),self.avgPixel,self.def)\n",
    "        if sum(sum(frame - self.AGMM.apply(frame,learningRate = 0))) / self.avgPixel < self.defocusThreshold:\n",
    "            self.defocusDelayQue.append(frameID)\n",
    "            if (defocus_delay(self.defocusDelayQue) and illumi_flag == 1) or illumi_flag == 0:\n",
    "                print(\" ===== At \", frameID,\" Defocus Detected ===== \",self.name)\n",
    "                return True,sum(sum(frame - self.AGMM.apply(frame,learningRate = 0))) / self.avgPixel\n",
    "        return False, sum(sum(frame - self.AGMM.apply(frame,learningRate = 0))) / self.avgPixel\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video = []\n",
    "file = sorted(glob.glob(\"C:/Users/Jimmy/Desktop/Everguard/Image Sabotage/jpgFile/Factory/1/*.jpg\"), key=os.path.getmtime)\n",
    "c = 0\n",
    "for frame in file:\n",
    "    \n",
    "    if c >= 4200 :\n",
    "        break\n",
    "    f = cv2.imread(frame)\n",
    "    video.append(f)\n",
    "    c = c + 1\n",
    "    #video.append(f[:int(f.shape[0]/2),:int(f.shape[1]/2)])\n",
    "print(len(video))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "situation = []\n",
    "\n",
    "windowTL = subWindow(name = \"TL\",illuminationThreshold = 10,textureThreshold = 8,apertureLength = 10,defocusThreshold = 0.4,shiftTolerence = 50,shiftRatio = 1,learningRate = 0.0001)\n",
    "windowTR = subWindow(name = \"TR\",illuminationThreshold = 10,textureThreshold = 8,apertureLength = 10,defocusThreshold = 0.4,shiftTolerence = 50,shiftRatio = 1,learningRate = 0.0001)\n",
    "windowBL = subWindow(name = \"BL\",illuminationThreshold = 10,textureThreshold = 8,apertureLength = 10,defocusThreshold = 0.4,shiftTolerence = 50,shiftRatio = 1,learningRate = 0.0001)\n",
    "windowBR = subWindow(name = \"BR\",illuminationThreshold = 10,textureThreshold = 8,apertureLength = 10,defocusThreshold = 0.4,shiftTolerence = 50,shiftRatio = 1,learningRate = 0.0001)\n",
    "\n",
    "allWindow = [windowTL,windowTR,windowBL,windowBR]\n",
    "\n",
    "init = 0\n",
    "kernel = np.ones((2,2),np.float32)/25\n",
    "frameID = 0\n",
    "shift_flag = 0\n",
    "\n",
    "\n",
    "for frame in video:\n",
    "    #print(frameID)\n",
    "    frameID = frameID + 1\n",
    "    #f = cv2.imread(frame)\n",
    "    f = frame\n",
    "    grey = cv2.cvtColor(f, cv2.cv2.COLOR_BGR2GRAY)\n",
    "    edge = cv2.Canny(grey,150,300)\n",
    "    #edge = grey\n",
    "    dilateEdge = cv2.dilate(edge,kernel)\n",
    "    \n",
    "    windowTL.cache.append(dilateEdge[:int(f.shape[0]/2),:int(f.shape[1]/2)])\n",
    "    windowTR.cache.append(dilateEdge[:int(f.shape[0]/2),int(f.shape[1]/2):])\n",
    "    windowBL.cache.append(dilateEdge[int(f.shape[0]/2):,:int(f.shape[1]/2)])\n",
    "    windowBR.cache.append(dilateEdge[int(f.shape[0]/2):,int(f.shape[1]/2):])\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    if frameID < 2000:        \n",
    "        windowTL.trainingCache.append(dilateEdge[:int(f.shape[0]/2),:int(f.shape[1]/2)])\n",
    "        windowTR.trainingCache.append(dilateEdge[:int(f.shape[0]/2),int(f.shape[1]/2):])\n",
    "        windowBL.trainingCache.append(dilateEdge[int(f.shape[0]/2):,:int(f.shape[1]/2)])\n",
    "        windowBR.trainingCache.append(dilateEdge[int(f.shape[0]/2):,int(f.shape[1]/2):])\n",
    "\n",
    "    else:\n",
    "        if init == 0:\n",
    "            init = 1\n",
    "            \n",
    "            for sw in allWindow:\n",
    "                sw.learningParam()\n",
    "                sw.illuminationModel = sw.construct_illumination_model(init=0)\n",
    "                sw.textureModel = sw.construst_GLCM_model(init=0)\n",
    "        else:\n",
    "            # Illumination Change detection \n",
    "            illumi_flag = False\n",
    "            tmpflag = False\n",
    "            for sw in allWindow:\n",
    "                tmpflag, value = sw.suddenIlluminationChangeDetection()\n",
    "                illumi_flag= illumi_flag or tmpflag\n",
    "            if illumi_flag:\n",
    "                print(\" =====  Illumination Change =====  \")\n",
    "            \n",
    "            \"\"\"# Shift Detection \n",
    "            tmpflag = False\n",
    "            shift_flag = False\n",
    "            \n",
    "            for sw in allWindow:\n",
    "                tmpflag, value = sw.shiftDetection(illumi_flag,frameID)\n",
    "                shift_flag = shift_flag or tmpflag\n",
    "                shift_value.append(value)\n",
    "                if shift_flag :\n",
    "                    print(\" == Shift == \",frameID, value )\n",
    "                    break\"\"\"\n",
    "            \"\"\"if TL.shiftDetection(tmptl,illumi_flag) or TR.shiftDetection(tmptr,illumi_flag) or LL.shiftDetection(tmpll,illumi_flag) or LR.shiftDetection(tmplr,illumi_flag):\n",
    "                print(\"Shifted\")\n",
    "                break\n",
    "            \"\"\"\n",
    "            \n",
    "            # Texture Change Detection\n",
    "            texturechangeflag = False\n",
    "            tmpflag = False\n",
    "            pending = 0\n",
    "            occlusion = 0\n",
    "            for sw in allWindow:\n",
    "                tmpflag, value = sw.suddenTextureChangeDetection(frameID)\n",
    "                #print(\"text V\",value,len(value),value[0])\n",
    "                texturechangeflag = texturechangeflag or tmpflag\n",
    "                if tmpflag: \n",
    "                    if aperture_effect(sw.occlusionDelayQue):\n",
    "                        occlusion = 1\n",
    "                        print(\" \\n===== At Frame \",frameID,\"Occlusion !! =====  \",sw.name,\"\\n\")\n",
    "                    else:\n",
    "                        pending = 1\n",
    "                        print(\" Time\",frameID,sw.name,\" Pending not sure if it's aperture effect\")\n",
    "                \n",
    "                else:\n",
    "                    sw.textureModelUpdate(illumi_flag,frameID)\n",
    "                    \n",
    "            \n",
    "            # Defocus Detection\n",
    "            tmpflag = False\n",
    "            defocusflag = False\n",
    "            for sw in allWindow:\n",
    "                tmpflag, value = sw.defocusDetection(illumi_flag,frameID)\n",
    "                defocusflag = defocusflag or tmpflag\n",
    "                if defocusflag:\n",
    "                    defocusflag = True\n",
    "                    print(\"\\n\\tSub or All Defocus Detected\\n\")\n",
    "            \"\"\"if TL.defocusDetection(tmptl,illumi_flag,frameID) or TR.defocusDetection(tmptr,illumi_flag,frameID) or LL.defocusDetection(tmpll,illumi_flag,frameID) or LR.defocusDetection(tmplr,illumi_flag,frameID):\n",
    "                print(\"\\n\\nSub or All Defocus Detected\\n\\n\")\"\"\"\n",
    "            \n",
    "            # outputframe\n",
    "            situation.append((occlusion,pending,defocusflag,shift_flag))\n",
    "            \n",
    "            \n",
    "        if frameID %100 == 0:\n",
    "            print(frameID)\n",
    "            plt.figure(figsize=(15,5))\n",
    "            plt.subplot(221)\n",
    "            plt.imshow(windowTL.cache[-1] - windowTL.AGMM.apply(windowTL.cache[-1],learningRate=0))\n",
    "            plt.subplot(222)\n",
    "            plt.imshow(windowTR.cache[-1] - windowTR.AGMM.apply(windowTR.cache[-1],learningRate=0))\n",
    "            plt.subplot(223)\n",
    "            plt.imshow(windowBL.cache[-1] - windowBL.AGMM.apply(windowBL.cache[-1],learningRate=0))\n",
    "            plt.subplot(224)\n",
    "            plt.imshow(windowBR.cache[-1] - windowBR.AGMM.apply(windowBR.cache[-1],learningRate=0))\n",
    "            \n",
    "            plt.show()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
